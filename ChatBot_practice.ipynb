{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import annoy\n",
    "import numpy as np\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import pickle\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('/home/gor/Downloads/ProductsDataset.zip', compression='zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "with codecs.open(\"prepared_answers.txt\",\"w\", \"utf-8\") as fout:\n",
    "    with codecs.open(\"Otvety.txt\", \"r\", \"utf-8\") as fin:\n",
    "        for line in tqdm(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading data for speaker into pd.DataFrame\n",
    "speaker_data = pd.read_csv(\n",
    "    '/home/gor/Downloads/prepared_answers.txt',\n",
    "    sep='\\t',\n",
    "    error_bad_lines=False,\n",
    "    names=['question', 'answer']\n",
    "    )\n",
    "# Drop NA - values\n",
    "speaker_data.dropna(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step - creating classificator \"speaker/product recommend\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "stop_words = get_stop_words('ru')\n",
    "punc_s = list(string.punctuation)\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    \"\"\" Fuction returns a list of words' lemmas \"\"\"\n",
    "    \n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = ''.join(i for i in text if i not in punc_s).split()\n",
    "    text = [morph.parse(i.lower())[0].normal_form for i in text] \n",
    "    text = [i for i in text if i not in stop_words]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exctracting questions from speaker-df\n",
    "questions_df = speaker_data.question.to_frame()\n",
    "# Make a label for the next modeling\n",
    "questions_df['label'] = 0\n",
    "\n",
    "# Similar actions for the product-df\n",
    "products_n_desc = pd.concat(\n",
    "    [products.title, products.descrirption],\n",
    "    ignore_index=True\n",
    ")\n",
    "products_n_desc = products_n_desc.to_frame(name='question')\n",
    "products_n_desc['label'] = 1\n",
    "\n",
    "# Concatenate both frames\n",
    "common_data = pd.concat([questions_df, products_n_desc], axis=0, ignore_index=True, join='outer')\n",
    "common_data.dropna(inplace=True)\n",
    "# Normalization and lemmatization of questions and descriptions in common dataframe\n",
    "common_data.question = common_data.question.apply(preprocessing_text)\n",
    "# Exctracting questions and desctriptions from common dataframe in list form\n",
    "to_vectorize =  common_data.question.tolist()\n",
    "# Create w2v - model for further vectorization of text\n",
    "w2v_common_model = Word2Vec(sentences=to_vectorize, min_count=1, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data.to_csv('/home/gor/Desktop/Projects/common_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_data = pd.read_csv('/home/gor/Downloads/common_data_v2.csv', dtype=list)\n",
    "w2v_common_model = Word2Vec.load('/home/gor/Downloads/common_model_v2.model')\n",
    "to_vectorize =  common_data.question.tolist()\n",
    "vectorized_df = pd.read_csv('/home/gor/Downloads/vectorized_v2.csv')\n",
    "vectorized_df['label'] = common_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data = pd.read_csv(\n",
    "    '/home/gor/Downloads/common_data_v2.csv',\n",
    "    names=['question', 'label'],\n",
    "    dtype={'question':'str', 'label':'int'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(line):\n",
    "    \"\"\" Function returns vector of words\n",
    "    which constits every line in dataframe \"\"\"\n",
    "\n",
    "    n2 = 0\n",
    "    vector = np.zeros(100)\n",
    "\n",
    "    for word in line:\n",
    "        if word in w2v_common_model.wv:\n",
    "            vector += w2v_common_model.wv[word]\n",
    "            n2 += 1\n",
    "        if n2 > 0:\n",
    "            vector = vector / n2\n",
    "        \n",
    "    \n",
    "    return vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_list = []\n",
    "\n",
    "for i in to_vectorize:\n",
    "    vectorized_list.append(get_vector(i))\n",
    "\n",
    "vectorized_df = pd.DataFrame(vectorized_list)\n",
    "vectorized_df['label'] = common_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df.to_csv('/home/gor/Desktop/Projects/vectorized.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling speaker/ product recommend classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Train shape - (986824, 100)\n",
      "Test shape - (246706, 100)\n"
     ]
    }
   ],
   "source": [
    "X = vectorized_df.drop('label', axis=1)\n",
    "y = vectorized_df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print('Done')\n",
    "print(f'Train shape - {X_train.shape}')\n",
    "print(f'Test shape - {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(l1_ratio=0.5, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;,\n",
       "                   warm_start=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(l1_ratio=0.5, penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;,\n",
       "                   warm_start=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(l1_ratio=0.5, penalty='elasticnet', solver='saga',\n",
       "                   warm_start=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga', penalty='elasticnet', warm_start=True, l1_ratio=0.5)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = lr.predict(X_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, predicted_test)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "        label='ROC кривая (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second step - creating models for products recommend system and speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data from common data\n",
    "preprocessed_speaker = common_data[common_data.label==0].question.reset_index(drop=True)\n",
    "preprocessed_speaker.shape[0] == speaker_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make product dataframe with product title and desctiprion which will\n",
    "# be as one feature\n",
    "\n",
    "with_titles = products.drop('descrirption', axis=1)\n",
    "with_desc = products.drop('title', axis=1).rename(columns={'descrirption':'title'})\n",
    "new_products = pd.concat([with_titles, with_desc])\n",
    "new_products.dropna(inplace=True)\n",
    "preprocessed_products = new_products.title.apply(preprocessing_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                product_id  category_id subcategory_id  \\\n",
       "0     Юбка детская ORBY  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1             Ботильоны  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2                 Брюки  59534826aaab284cba337e06          9.0            906   \n",
       "3  Продам детские шапки  57de544096ad842e26de8027         22.0           2217   \n",
       "4                Блузка  5ad4d2626c86cb168d212022          9.0            907   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "\n",
       "                                         image_links  \n",
       "0  http://cache3.youla.io/files/images/360_360/58...  \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "2  http://cache3.youla.io/files/images/360_360/59...  \n",
       "3  http://cache3.youla.io/files/images/360_360/57...  \n",
       "4  http://cache3.youla.io/files/images/360_360/5a...  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_products.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product and speaker indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_model = Word2Vec(sentences=preprocessed_products, min_count=1, vector_size=100)\n",
    "speaker_model = Word2Vec(sentences=preprocessed_speaker, min_count=1, vector_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834f96927f1147c69825c45ee96fb68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_index(df, model, vector_len=100, par='angular', n_trees=10):\n",
    "    \"\"\" Function return annoy-index from input dataframe/series\"\"\"\n",
    "\n",
    "    new_index = annoy.AnnoyIndex(vector_len, par)\n",
    "    counter = 0\n",
    "\n",
    "    for line in tqdm(df):\n",
    "        n_w2v = 0\n",
    "        vector = np.zeros(vector_len)\n",
    "        for word in line:\n",
    "            if word in model.wv:\n",
    "                vector += model.wv[word]\n",
    "                n_w2v += 1\n",
    "        if n_w2v>0:\n",
    "            vector = vector / n_w2v\n",
    "        \n",
    "        new_index.add_item(counter, vector)\n",
    "        counter += 1\n",
    "\n",
    "    new_index.build(n_trees)\n",
    "    return new_index\n",
    "    \n",
    "product_index = make_index(df=preprocessed_products, model=product_model)\n",
    "speaker_index = make_index(df=preprocessed_speaker, model=speaker_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#speaker_model.save('/home/gor/Desktop/Projects/Speaker_recommend_bot/speaker_model.model')\n",
    "#product_model.save('/home/gor/Desktop/Projects/Speaker_recommend_bot/product_model.model')\n",
    "#product_index.save('/home/gor/Desktop/Projects/Speaker_recommend_bot/product_index.ann')\n",
    "#speaker_index.save('/home/gor/Desktop/Projects/Speaker_recommend_bot/speaker_index.ann')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(inp_data):\n",
    "    \"\"\" Function returns class-value for input data\n",
    "    0 - speaker, 1 - product \"\"\"\n",
    "    \n",
    "    inp_data = preprocessing_text(inp_data)\n",
    "    data_vector = get_vector(inp_data)\n",
    "    data_vector = data_vector.reshape(1,-1)\n",
    "    return lr.predict(data_vector)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                product_id  category_id subcategory_id  \\\n",
       "0     Юбка детская ORBY  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1             Ботильоны  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2                 Брюки  59534826aaab284cba337e06          9.0            906   \n",
       "3  Продам детские шапки  57de544096ad842e26de8027         22.0           2217   \n",
       "4                Блузка  5ad4d2626c86cb168d212022          9.0            907   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "\n",
       "                                         image_links  \n",
       "0  http://cache3.youla.io/files/images/360_360/58...  \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "2  http://cache3.youla.io/files/images/360_360/59...  \n",
       "3  http://cache3.youla.io/files/images/360_360/57...  \n",
       "4  http://cache3.youla.io/files/images/360_360/5a...  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, model=product_model, index=product_index, path=new_products['product_id']):\n",
    "\n",
    "    if classifier(question)==0:\n",
    "        model = speaker_model\n",
    "        index = speaker_index\n",
    "        path = speaker_data['answer']\n",
    "\n",
    "    preprocessed_question = preprocessing_text(question)\n",
    "\n",
    "    n_w2v = 0\n",
    "    vector = np.zeros(100)\n",
    "\n",
    "    for word in preprocessed_question:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            n_w2v += 1\n",
    "    if n_w2v > 0:\n",
    "        vector = vector / n_w2v\n",
    "    answer_index = index.get_nns_by_vector(vector, 1)\n",
    "\n",
    "    print(path.iloc[answer_index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "58cd08378ae74be99ef57dfd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gor/miniconda3/envs/condaDS/lib/python3.9/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/gor/miniconda3/envs/condaDS/lib/python3.9/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_answer('юбка orby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Як. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gor/miniconda3/envs/condaDS/lib/python3.9/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/gor/miniconda3/envs/condaDS/lib/python3.9/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "get_answer('где ключи от танка')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
